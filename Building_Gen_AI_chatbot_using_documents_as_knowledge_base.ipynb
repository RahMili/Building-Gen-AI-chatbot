{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Hi, this notebook is part of the article \"Building Gen AI chatbot using documents as knowledge base\" Link to article: https://medium.com/@rahulmili277/building-genai-chatbot-for-querying-documents-38f80de5796e\n",
        "\n",
        "\n",
        "Please follow the instructions to run this notebook, you will be required to create a directory and upload documents that will be used as knowledge base for answering queries\n",
        "\n",
        "1. Create a directory called 'documents' in '/content'\n",
        "2. Upload the pdf or text documents inside this directory"
      ],
      "metadata": {
        "id": "2iXC9MQlzoV4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZroeSf1HznlO"
      },
      "outputs": [],
      "source": [
        "# lets install the dependencies\n",
        "!pip install google-cloud-aiplatform\n",
        "!pip install pypdf\n",
        "!pip install langchain\n",
        "!pip install shapely==2.0.0\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart the runtime after running the above cell\n",
        "\n",
        "Authenticate your google account"
      ],
      "metadata": {
        "id": "YTqQeUEf2I77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "VrnGtDur2TbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "text_utils -> Please refer the article to read about this function"
      ],
      "metadata": {
        "id": "-u2tiDRm2hYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "\n",
        "def context_extractor(file_path):\n",
        "    text_extensions = ['.txt', '.csv']  # Add more text extensions if needed\n",
        "    pdf_extensions = ['.pdf']  # Add more PDF extensions if needed\n",
        "    text = ''\n",
        "    file_extension = os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "    if file_extension in text_extensions:\n",
        "        with open(file_path, 'r') as file:\n",
        "            text = file.read()\n",
        "        return text\n",
        "    elif file_extension in pdf_extensions:\n",
        "        text = ''\n",
        "        pdf_loader = PyPDFLoader(file_path)\n",
        "        pages = pdf_loader.load_and_split()\n",
        "        for i in pages:\n",
        "            text = text +\"\\n\\n\" + i.page_content\n",
        "        return text\n",
        "    else:\n",
        "        return 'Unknown file type'"
      ],
      "metadata": {
        "id": "mK5wtanv2TYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "files_util -> parses your directory and sends the paths as argument to above function"
      ],
      "metadata": {
        "id": "hic5Gt4i25W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_file_paths(directory):\n",
        "    file_paths = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            file_paths.append(file_path)\n",
        "    return file_paths"
      ],
      "metadata": {
        "id": "Fg6DAbZG2S1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create_context -> please refer the article to read about this function"
      ],
      "metadata": {
        "id": "ZDA5mJxN3IrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "def create_context(dir_path):\n",
        "  file_paths = get_file_paths(dir_path)\n",
        "  texts_list = []\n",
        "  for file_path in file_paths:\n",
        "      print(file_path)\n",
        "      text = context_extractor(file_path)\n",
        "      text_splitter = CharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
        "      context = text\n",
        "      texts = text_splitter.split_text(context)\n",
        "      for i in texts:\n",
        "        texts_list.append(i)\n",
        "  for chunk_index, chunk in enumerate(texts_list):\n",
        "      # print(chunk)\n",
        "      # Create a unique file name for each chunk\n",
        "      chunk_file_name = f\"/content/chunks/chunk_{chunk_index}.txt\"\n",
        "\n",
        "      # Save the chunk as a text file\n",
        "      with open(chunk_file_name, 'w') as file:\n",
        "          file.write(chunk)\n",
        "\n",
        "      # Print the file path of the saved chunk\n",
        "      print(f\"Saved chunk {chunk_index} as {chunk_file_name}\")"
      ],
      "metadata": {
        "id": "Nc0AWJx-3N7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "read_chunks -> reads the saved chunks from the saved directory and loads them in memory"
      ],
      "metadata": {
        "id": "dNmDACEj3WV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_chunks(dir_path):\n",
        "    context_paths = get_file_paths(dir_path)\n",
        "    chunks = []\n",
        "    for context_path in context_paths:\n",
        "        with open(context_path, 'r') as file:\n",
        "            chunk = file.read()\n",
        "            chunks.append(chunk)\n",
        "            print(chunk)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "P1uedK9b3vfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell to implement the chatbot, it will extract the text, create chunks, load them in memory, create embeddings and make the chunks ready for querying"
      ],
      "metadata": {
        "id": "APtQeK-935o8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "import warnings\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.vectorstores import Chroma\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "PROJECT_ID = \"YOUR_PROJECT_ID\"\n",
        "REGION = \"PROJECT_REGION\"\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "# parameters for model\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 380,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "\n",
        "\n",
        "#getting the text model\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "vertex_embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")\n",
        "\n",
        "# pass the path to diectory containing documents\n",
        "create_context('/content/documents')\n",
        "\n",
        "# load chunks\n",
        "chunks = read_chunks('/content/chunks')\n",
        "\n",
        "# create embeddings from chunks\n",
        "vector_index = Chroma.from_texts(chunks, vertex_embeddings).as_retriever()\n"
      ],
      "metadata": {
        "id": "1Fu6-Dqs36O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the driver code, which will query the LLM and generate the responses, you can modify the prompt as needed for your case."
      ],
      "metadata": {
        "id": "jbwNMxVI_i77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main driver function\n",
        "def run_query(question):\n",
        "    # get the chunks having possibility of containing answer\n",
        "    docs = vector_index.get_relevant_documents(question)\n",
        "    answers = ''\n",
        "    for i in docs:\n",
        "        # query the LLM\n",
        "        response = model.predict(\n",
        "          f\"Answer the question as precise as possible using the provided context.\\\n",
        "           If the answer is not contained in the context, say 'answer not available \\\n",
        "           in context'. \\n\\n Context: \\n {i.page_content} \\nQuestion: \\n {question} \\n\",\n",
        "          **parameters\n",
        "        )\n",
        "        # append the answers\n",
        "        answers = answers + \"\\n\\n\" + response.text\n",
        "\n",
        "    final_response = model.predict(\n",
        "        f\"Given the extracted content and the question, create a conversational \\\n",
        "        final answer. If the answer is not contained in the context or if the context\\\n",
        "         is empty then, say 'answer not available in context'. \\n\\n Context: \\n \\\n",
        "         {answers} \\nQuestion: \\n {question} \\n\",\n",
        "        **parameters\n",
        "        )\n",
        "    return final_response.text"
      ],
      "metadata": {
        "id": "48DT62Dw_buG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell and pass the question you want to ask from the documents"
      ],
      "metadata": {
        "id": "ZohRwTtl6xgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_query(\"Ask your question here\"))"
      ],
      "metadata": {
        "id": "qNz-k1-I_1y5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}